各聚类算法在数据集上的应用。数据来源于统计学、计算机科学、机器学习。

力求提供一个易理解和系统的描述，这些聚类算法的影响性与重要性。

introduction写的很好。

Section 1
解决两个很好的问题：
1. 如何设定合适的度量。
2. 如何确定类簇的数量。


Section 2
1. 层次聚类与划分聚类的关系。
2. 划分需要知道K的大小。

2-A 度量
3. 聚类的基础是度量。
4. 数据对象（记录）常被表示为多维向量。
5. 距离函数特性。
6. 相似性函数特性。
7. 距离函数连续特征，相似性函数计算定性特征。
8. 二元特征的距离与相似度。
9. 其他特征转换为二元特征（无详细）。

2-B 层次聚类
10. 叶节点是数据对象。
11. 内部节点则是一个划分，节点中的数据对象类似。
12. 树的高度代表了对象之间的距离。
13. 在不同层次剪断，可以得到聚类结果。
14. 层次聚类分为凝聚聚类和分裂聚类（成本大，不常用）。
15. 经典的层次聚类算法缺乏鲁棒性、对噪音和异常点敏感。
16. 新的层次聚类算法如BIRCH适合大规模数据以及提高了对异常点的鲁棒性。
17. 新的层次聚类算法使用聚类特征树。

2-C 基于平方误差的聚类
18. 划分聚类是在没有层次结构下，把数据对象集合划分到K个类。
19. 最优划分可以通过枚举所有可能得到，但是暴力是不现实的。
20. 判别函数（criterion function）是划分聚类的重要因素。
21. 平方误差函数是广泛使用的判别函数。
22. 平方误差定义：划分矩阵误差的平方和，需要划分矩阵和中心矩阵。
23. K-means是典型代表。
24. K-means可以大规模数据，并行技术可以加速算法。
25. K-means缺点：a.没有高效的方法确定K。b.非全局最优。c.对噪音和异常点敏感。d.只应用于数值特征。
26. K-medoids解决K-means的缺点c与缺点d。

2-D 基于最大化密度的聚类
----未读----

2-E 基于图论的聚类
----未读----

2-F 基于组合搜索技术的聚类
27. 致力于寻求全局最优，但这是NP问题。

2-G 模糊聚类
28. 对象可以属于所有的类，但他与任何一个类之间的关系都有一个度量。
29. 适合于边界不明显的聚类。
30. FCM是最流行的模糊聚类，来源于ISODATA，对噪音和异常点敏感。
31. FCM已存在很多变种。

2-H 神经网络聚类
32. 主宰算法SOFMs和ART。
----未细读----

2-I 内核聚类
33. kernel trick。
34. kernel-K-means。
35. 优点众多。

2-J 序列数据聚类
36. 序列数据来源：基因序列，文本挖掘，医疗诊断，股票市场，用户交易等等。
37. 该类算法分三类：序列相似性、间接序列聚类、统计序列聚类。

2-K 大规模数据聚类
38. 层次聚类不适合，K-means适合（变种可以克服缺点）。
39. 一些标称算法适合。

2-L 数据可视化与高维数据
40. curse of dimensionality
41. PCA，ICA，MDS，LLE

2-M 如何确定有多少类
42. 经验估计
43. 数据可视化，适用于简单的数据，将多维映射到多幅二维图
44. 构造某些索引
45. 在概率混合模型框架下，优化判别函数：给了一堆K，找期中最优的
46. 其他启发性方法
