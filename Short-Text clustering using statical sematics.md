# 基于统计语义学的短文本聚类

## 摘要

矩阵稀疏，文本相似度接近0.作者提出了合并词条间合并信息，来增强短文本片段的表达。

如果两个短文本段没有相同的单词，但是第一个短文本段的词条与来自第二个短文本段的词条同时出现的比较频繁，这两个短文段的度量应当比较高。

为了避免大量的计算，将对样本抽样。并且使用Nystrom方法来近似term-term的相关矩阵。


## 前言

推文是典型的短文本。
短文本聚类更加具有挑战：稀疏性和噪音。它们提供的上下文相关的线索很少。

VSM：向量空间模型，词条是独立的，并且忽视了词条之间的语义关系。
VSM的新奇在于使用词典的频率发现语义信息。
VSM的思想是使用向量空间中的点来代替每一个文档。相近的点的语义是相近的。

GVSM，内积或余弦相似度作为词条之间的相关性。协方差矩阵和相关系数矩阵也可以用来作为词条的相关度量。

本文使用了词条之间的相关性，然而，为了避免计算所有词条的相关性而引发的高计算时间，使用Nystrom近视法。Nystrom近似法使用一些词条近似整个的词条-词条相似矩阵。使用随机抽样为Nystrom选择词条。**随机抽样具体方案为：词条所占的比例概率抽样，分母为文档空间中他们的向量的长度**。

## 相关工作

短文本分类需要大量的训练样本才能获得高的精确度。所以采用聚类。

修改词条的权重。一个词条的权重与每一个词条都有关系。为了是聚类过程更高效，是需要将向量标准化。那些重要的词条拥有更高的权值，常用方案是使用tf-idf。

针对短文本也提出了许多权值方法。
1. Yan等提出。短文本使用tf-idf并不高效，由于稀疏性，使用所有文档中的词条频率来捕捉数据的区别性，并不是一个好的方法。他们在词条级别而不是文档级别测量词条的区别性。建立图模型，使用Ncut进行划分。
2. 使用明确的和外部的语义。通过合并一些外部的知识，比如引入外部词典，这样可以使用外部语义。一些人提出了使用维基百科的方法，但是比价复杂。
3. 其他的方法增强聚类通过使用明确的内部语义，比如term-term相似性。一种可能的方法是扩展特征。使用共同出现的信息，评估词条间的关系。基于这样的观点：如果两个词条经常同时出现在文档中，那么这两个词条是相似的。因此，一个词条可以使用一个词条共同出现向量表示，而不是文档向量。同时考虑的词条的共同出现与依赖性。计算每对词条共同出现的权值，基于此决定两个词条是否在相同的簇。**（那得到的不就是词条簇吗？如何将文档分类）**

短文本的相关矩阵非常稀疏，由于稀疏性，聚类效率也显著下降。SVD是对空缺数据的一种修正，它同时能够使我们处理大规模的数据。

## 本文方法

当只有有限的知识可以使用时，发现短文本中词条间的相关性尤其重要。

统计语义学，是测量词条间相似性的一种方法。它基于词条共同出现模式的统计分析。由Farahat and Kamel提出，Statistical semantics for enhancing document clustering。

**segments在本文中到底指的什么么。**

shape of X：(m,n)
Xij: weight of term i inside document j.

设计X，G，Z等矩阵之间的关系。

使用本方法的主要限制来自计算词条-词条的相关性。

作者提出选择一些词条而不是使用文档，然后使用这些词条和Nystrom方法近似词条-词条相关矩阵X。

选择方法：用被选择的词条集合S代替term-term矩阵G。

l：被选择的词条的数量。

## 实验

数据集：带标签的推文，推文来自Zubiaga整理，自动贴标签根据推文中所包含URL所指向网页的内容，ODP作为标签集合。数据集360K（36万）。

实验数据大小从1万到10万不等。


基准线方法：（拿来做对比使用）
- K-means，加权tf-idf
- SphericalK-means，使用余弦相似度，这种方案独立于文档的长度。
- Non-negative Matrix Factorization（NMF），加权tf-idf+Ncut


图1：l增加，kmeans与skmeans的NMI评估值都保持不变，kmeans低于skmeans。
图2：l增加，kmeans与skmeans的时间消耗保持不变。

图3：使用NMF的情况下，l增加，nmf与Ncut+nmf的NMI保持不变，nmf高于Ncut+nmf。
图4：使用NMF的情况下，l增加，nmf与Ncut+nmf的时间消耗保持不变，nmf**远低于**Ncut+nmf。


红色才是作者提出的方案。
作者提出的term-term矩阵可以被assc，asscn，cov，pcor使用。

assc与pcor耗时都差不多啊。


## 结果与分析

然而并没特别看懂。

参数k与rank有关系，何时提到rank了？




















